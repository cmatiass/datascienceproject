# ğŸš€ Data Science Project - Structured ML Pipeline

## ğŸ“Œ Overview
This project focuses on the proper structuring of a Data Science pipeline. It is designed to ensure modularity by breaking down different stages of machine learning workflows into separate modules. The pipeline is executed in the following stages:

1. **ğŸ“¥ Data Ingestion** - Collecting and loading data into the pipeline.
2. **âœ… Data Validation** - Ensuring data quality and consistency.
3. **ğŸ”„ Data Transformation** - Preprocessing and feature engineering.
4. **ğŸ¤– Model Training** - Training machine learning models.
5. **ğŸ“Š Model Evaluation** - Assessing model performance.

A web application (`app.py`) has been implemented to allow users to make predictions using the trained model. ğŸ–¥ï¸

## ğŸ¯ Project Goals
The main objective of this project is to demonstrate a well-structured Data Science workflow while maintaining a modular design. **It does not include data preprocessing or an exploratory data analysis (EDA) since the focus is solely on project structure and model deployment.** A sample dataset has been used for demonstration purposes.

## ğŸ› ï¸ Steps to Set Up the Project
To replicate this project, follow these steps:

1. **ğŸ“‚ Create a GitHub Repository**
2. **ğŸ“¥ Clone the Repository Locally**, add `.gitignore`, commit changes, and push to origin.
3. **âš™ï¸ Set Up a Conda Environment** and activate it.
4. **ğŸ“¦ Install Dependencies** listed in `requirements.txt`.
5. **ğŸ“ Create `template.py`** to define the folder and file structure.
6. **ğŸ“œ Configure Logging** in `logs/logging.log`.
7. **ğŸ”§ Create Common Utility Functions** in `common.py`.
8. **âš™ï¸ Configure `config.yaml`** to manage pipeline settings.
9. **ğŸ› ï¸ Develop Classes and Functions** for each stage in `src/datascience/components/`.
10. **ğŸŒ Implement the Web App (`app.py`)** for real-time predictions.

## ğŸ“ Directory Structure
```
â”‚   .gitignore                      # Specifies files to be ignored by Git
â”‚   app.py                          # Flask web application entry point
â”‚   Dockerfile                      # Container definition for Docker deployment
â”‚   generate_structure.py           # Script to generate directory structure
â”‚   LICENSE                         # Project license information
â”‚   main.py                         # Main entry point for the application
â”‚   params.yaml                     # Model parameters configuration
â”‚   README.md                       # Project documentation and overview
â”‚   requirements.txt                # Python package dependencies
â”‚   schema.yaml                     # Data schema definition
â”‚   setup.py                        # Package installation script
â”‚   struct.txt                      # Project structure listing
â”‚   struct_files.txt                # Alternative project structure file
â”‚   template.py                     # Template file for code generation
â”‚
â”œâ”€â”€â”€.github                         # GitHub specific configurations
â”‚   â””â”€â”€â”€workflows                   # CI/CD workflow definitions
â”‚
â”œâ”€â”€â”€artifacts                       # Generated files during pipeline execution
â”‚   â”œâ”€â”€â”€data_ingestion              # Files from data ingestion step
â”‚   â”œâ”€â”€â”€data_transformation         # Files from data transformation step
â”‚   â”œâ”€â”€â”€data_validation             # Files from data validation step
â”‚   â”œâ”€â”€â”€model_evaluation            # Files from model evaluation step
â”‚   â””â”€â”€â”€model_trainer               # Files from model training step
â”‚
â”œâ”€â”€â”€config                          # Configuration files
â”‚
â”œâ”€â”€â”€logs                            # Application logs
â”‚
â”œâ”€â”€â”€research                        # Jupyter notebooks for research and experimentation
â”‚
â”œâ”€â”€â”€src                             # Source code
â”‚   â””â”€â”€â”€datascience                 # Main package
â”‚       â”œâ”€â”€â”€components              # Core ML pipeline components
â”‚       â”œâ”€â”€â”€config                  # Internal configuration handling
â”‚       â”œâ”€â”€â”€constants               # Constant values used across the project
â”‚       â”œâ”€â”€â”€entity                  # Data entity definitions
â”‚       â”œâ”€â”€â”€pipeline                # ML workflow pipelines
â”‚       â”œâ”€â”€â”€utils                   # Utility functions
â”‚       â””â”€â”€â”€__pycache__             # Python cached bytecode files
â”‚
â”œâ”€â”€â”€static                          # Static web files
â”œâ”€â”€â”€templates                       # HTML templates for web UI
â””â”€â”€â”€venv                            # Python virtual environment
```

## ğŸ› ï¸ Technologies Used
- ğŸ Python
- ğŸŒ Flask (for the web application)
- ğŸ§® Pandas, NumPy (for data processing)
- ğŸ¤– Scikit-learn (for machine learning)
- ğŸ’¾ Joblib (for model serialization)
- âš™ï¸ PyYAML (for configuration management)
- ğŸ“œ Logging (for application logs)
- ğŸ³ Docker (for containerization)
- ğŸ› ï¸ **DagsHub & MLFlow** (for experiment tracking and reproducibility)

## â–¶ï¸ How to Run
To run the project locally:

```bash
# Clone the repository
git clone <repository-url>
cd <repository-folder>

# Create and activate the environment
conda create --name ds_project python=3.10 -y
conda activate ds_project

# Install dependencies
pip install -r requirements.txt

# Run the pipeline
python main.py

# Run the web application
python app.py
```

## ğŸŒ How to Use the Web Application
Once the application is running, follow these steps:

1. **Access the main page**: Open your browser and go to `http://127.0.0.1:8080/`.
2. **Train the model**: Navigate to `http://127.0.0.1:8080/train`. This will execute the full pipeline, from data ingestion to model training.
3. **Return to the main page**: Go back to `http://127.0.0.1:8080/`.
4. **Make a prediction**: Enter values for each variable in the form and click on the `Predict` button.
5. **View the result**: The application will redirect you to `http://127.0.0.1:8080/predict`, where the predicted outcome will be displayed.

## ğŸ“ˆ Experiment Tracking with DagsHub & MLFlow
All executions of the model are tracked using **MLFlow** and are accessible through the **Experiments** section of **DagsHub**. This allows users to:
- View all previous model runs and their respective parameters.
- Compare performance metrics across different executions.
- Access logs and artifacts stored from each experiment.

This ensures full transparency, version control, and reproducibility of the ML workflow. ğŸš€ğŸ“Š

## ğŸ¤ Contribution
Contributions are welcome! Feel free to fork the repository, make modifications, and create a pull request.

---

This project serves as a template for well-structured Data Science projects, ensuring scalability and maintainability. ğŸš€âœ¨

